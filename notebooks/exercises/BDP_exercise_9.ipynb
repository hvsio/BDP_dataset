{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Processes - Exercise No. 9\n",
    "# <font color= green>Decision Trees <font color= black> & </font>Random Forest <font color= black> & </font> Boosting and Bagging</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color = green>Data preparation\n",
    "    \n",
    "<br>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <font color= orange>Importing various libraries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> First, we import some libraries. We rely on the usual pandas and numpy packages moreover, in order to create models, we are going to use Sklearn, as usual. Matplotlib is imported to display our results.\n",
    "\n",
    "<br>There are two ways to import a library. Either import the whole package by **import library_name**, but it may take time. If you know exactly what part (class) of the package you need, you can directly specify it by using the **from library_name import class_name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Libraries to work with the data object\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# libraries to visualize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn as one of the most used machine learning package\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. <font color= orange>Load and process the dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Again, we are using the **Auto** dataset that we also used for Linear and Logistic Regression. After loading and reading, we do some minor data cleaning and add the binary variable **mpg_binary** to be used as a label for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "path = 'Auto.csv'\n",
    "df = pd.read_csv(path, sep=';',encoding='utf-8', header = 0)\n",
    "\n",
    "#replace separator and change data type\n",
    "df['mpg'] = df['mpg'].str.replace(',','.').astype('float')\n",
    "df['acceleration'] = df['acceleration'].str.replace(',','.').astype('float')\n",
    "df['displacement'] = df['displacement'].str.replace(',','.').astype('float')\n",
    "\n",
    "#create binary variable \n",
    "df['mpg_binary'] = (df['mpg'] >= df['mpg'].median()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= #b300b3>Take a closer look at the data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Examine the X and y dataframes we have just created using the **.head()** and **.info()** functions, just as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> The target variable, y has classes, and they are in order. Therefore, if we display the last values of the target variable, we see the maximum number in classes. Since it is 1 and numbering in python starts from 0, our target variable has 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Look a bit more in depth at your variables... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = df[['horsepower','year','cylinders','acceleration']].values\n",
    "y = df['mpg_binary'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=  #b300b3> Create the holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>An important issue might arise knowing that the vectors, both target and feature are ordered. Therefore, if we split them into train and test datasets, what guarantees that both sets will include all labels and all type of feature vectors? **Luckily the train_test_split() method takes care of this by random shuffling the data before applying this split.**\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>We can make sure about it by checking one of the new vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color = green>Decision Tree\n",
    "   \n",
    "    \n",
    "<br>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <font color= orange>Create Decision Tree classification </font> by Sklearn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>The Sklearn default implementation uses Gini impurity to split on the given attributes. It can be easily transformed by changing the **criterion** parameter from **gini** to **entropy**, if you want to use information gain as a splitting criteria. Read the documentation for more insight. \n",
    "    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://miro.medium.com/max/1275/0*0dN6d8THyImxwPeD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 1.: </font> **Make an object** from the model's class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3 > Here **max_depth** refers to the maximum number of levels of the tree, excluding the topmost node. The default value is None, meaning that it will continue splitting until all nodes are leaf nodes. We are limiting the **max_depth** to prevent it from overfitting. \n",
    "    \n",
    "Explore with different depths and check the documentation to understand the default parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# first, create an object of the DecisionTreeClassifier() class\n",
    "model_DT = DecisionTreeClassifier(max_depth = 5, criterion = 'entropy')\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 2.: </font>**Fit** your model object on you data, which is the feature vectors (X) and the target vector (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# then apply the .fit() method on the object\n",
    "model_DT.fit(X_train,y_train)\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "tree.plot_tree(model_DT.fit(X_train, y_train))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 3.: </font>**Make prediction** on the (new / unseen) **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Let's measure our model's **accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# measure the accuracy and print it\n",
    "accuracy_train = round(model_DT.score(X_train,y_train),4)\n",
    "accuracy_test = round(model_DT.score(X_test,y_test),4)\n",
    "\n",
    "print(\"The model's accuracy for the train data is: \\t\", accuracy_train)\n",
    "print(\"The model's accuracy for the test data is: \\t\", accuracy_test)\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= #b300b3>Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Print out the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "prediction = model_DT.predict(X_test)\n",
    "print(\"Confusion matrix for model_dt on test set: \\n\\n\", confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color = green> Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \n",
    "    \n",
    "Behold! Documentation!\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <font color= orange> Create Random forest classification </font> by Sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= #b300b3> Building the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 1.: </font> **Make an object** from the model's class.\n",
    "    \n",
    "Here **n_estimators** represents the number of trees in the forest, the default value is 100. Again, we limit this number in order to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_RF = RandomForestClassifier(n_estimators = 5, max_depth = 5)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 2.: </font>**Fit, or train**,  your model object on your** training data**, which is the feature vectors (X_train) and the target vector (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 3.: </font>**Make prediction** on the (new / unseen) **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> Let's measure the accuracy score for both test and train data and print the confusion matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# measure the accuracy and print it\n",
    "accuracy_train = round(model_RF.score(X_train,y_train),4)\n",
    "accuracy_test = round(model_RF.score(X_test,y_test),4)\n",
    "\n",
    "print(\"The model's accuracy for the train data is: \\t\", accuracy_train)\n",
    "print(\"The model's accuracy for the test data is: \\t\", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= #b300b3>Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Let's print out the confusion matrix for the prediction the the **train set**. What would you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "prediction = model_RF.predict(X_train)\n",
    "print(\"Confusion matrix for model_RF on train set: \\n\\n\",confusion_matrix(y_train, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Let's print out the confusion matrix for the prediction the the **test set**. What would you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "prediction = model_RF.predict(X_test)\n",
    "print(\"Confusion matrix for model_RF on test set: \\n\\n\",confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color = green> Bagging and Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. <font color= orange>Create Bagging and Boosting classifiers <font color = black > by Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Let's import two new libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= #b300b3> Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 1.: </font> **Make an object** from the model's class.\n",
    "\n",
    "Signification of the parameters for Bagging and AdaBoost:\n",
    "\n",
    "**max_samples** is the number of samples to draw from X in order to train each decision tree (base estimator) \n",
    "\n",
    "**max_features** is the number of features to draw from X in order to train each decision tree (base estimator) \n",
    "\n",
    "**n_estimators** the number of decision trees(base estimators) in the ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_BG = BaggingClassifier(DecisionTreeClassifier(), max_samples = 0.5, max_features = 1.0, n_estimators = 2)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "\n",
    "model_BO = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = 2)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 2.: </font>**Fit, or train**,  your model object on your** training data**, which is the feature vectors (X_train) and the target vector (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_BG.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_BO.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 3.: </font>**Make prediction** on the (new / unseen) **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# measure the accuracy and print it\n",
    "accuracy_BG = round(model_BG.score(X_test,y_test),4)\n",
    "accuracy_BO = round(model_BO.score(X_test,y_test),4)\n",
    "\n",
    "print(\"The Bagging model's accuracy on the test data is: \\t\", accuracy_BG)\n",
    "print(\"The Boosting model's accuracy on the test data is: \\t\", accuracy_BO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= #b300b3>Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "prediction = model_BG.predict(X_test)\n",
    "print(\"Confusion matrix for model_BG on test set: \\n\\n\", confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "prediction = model_BO.predict(X_test)\n",
    "print(\"Confusion matrix for model_BO on test set: \\n\\n\", confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color = green> Multiple Model Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. <font color= orange>Trying out 3 different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>You already have the **DecisionTreeClassifier** as **DT**. Let's import the libraries and fit two other classifiers on this data: **Linear Regression** and **K Nearest Neighbor**. In addition we also import the **VotingClassifier** to find the best classification algorithm and the **StandardScaler** for standardizing the data used for the **KNN** classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= #b300b3> Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 1.: </font> **Make an object** from the model's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression(solver='liblinear')\n",
    "model_KNN = KNeighborsClassifier()\n",
    "model_DT = DecisionTreeClassifier()\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 2.: </font>**Fit, or train**,  your model object on your** training data**, which is the feature vectors (X_train) and the target vector (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_LR.fit(X_train,y_train)\n",
    "model_KNN.fit(X_train,y_train)\n",
    "model_DT.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. <font color= orange>Apply the VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 1.: </font> **Make an object** from the model's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "VC = VotingClassifier(estimators= [(\"model_LR\",model_LR),(\"model_KNN\", model_KNN),(\"model_DT\", model_DT)], voting = 'hard')\n",
    "# voting = 'hard' -> vote is on the labels and not the probabilities\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 2.: </font>**Fit, or train**,  your model object on your** training data**, which is the feature vectors (X_train) and the target vector (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "VC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3><font color = red>Creating a model, step 3.: </font>**Make prediction** on the (new / unseen) **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "VC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= #b300b3> Understanding the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> Using the **.transform**() method, we can get the prediction for each classifier. If we put the final prediction of the voting process and the actual target labels, we get a really nice overview of our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.concatenate([VC.transform(X_test), VC.predict(X_test).reshape(-1,1), y_test.reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>If numpy arrays are hard to read, let's create a pandas dataframe, to which we are got used to already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.concatenate([VC.transform(X_test), VC.predict(X_test).reshape(-1,1), y_test.reshape(-1,1)], axis=1), columns = ['model_RL', 'model_KNN', 'model_DT', 'Prediction', 'Truth'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Having these data in one dataframe opens endless opportunities to discover it further... Just recall our processes from the data cleaning classes.\n",
    "<br>\n",
    "    \n",
    "For example, we can create an extract for those lines in which the voted prediction differs from the actual target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "results_diff = results.loc[results['Prediction'] != results['Truth']]\n",
    "results_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>Using the same method, let's put the number of differences and matches for each classifier and the actual target label into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "difference_dict = {'model_RL': results['model_RL'][results['model_RL'] != results['Truth']].count(),\n",
    "                'model_KNN':results['model_KNN'][results['model_KNN'] != results['Truth']].count(),\n",
    "                'model_DT': results['model_DT'][results['model_DT'] != results['Truth']].count()}\n",
    "\n",
    "match_dict = {'model_RL': results['model_RL'][results['model_RL'] == results['Truth']].count(),\n",
    "                'model_KNN':results['model_KNN'][results['model_KNN'] == results['Truth']].count(),\n",
    "                'model_DT': results['model_DT'][results['model_DT'] == results['Truth']].count()}\n",
    "\n",
    "print(\"Number of different predictions: \\t\", difference_dict)\n",
    "print(\"Number of matching predictions: \\t\", match_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= black>What model would you take?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E1.** Think about whether you can apply a DecisionTree, Bagging and Boosting on your own dataset. (Think hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = green>That's it! Have a nice weekend once you are done progressing in your groups. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
